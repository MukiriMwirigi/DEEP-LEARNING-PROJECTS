{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6067bf19",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "428878b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "import utils_multiMNIST as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_dir = '../Datasets/'\n",
    "use_mini_dataset = True\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 42, 28 # input image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c445b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension):\n",
    "        super(CNN, self).__init__()\n",
    "        #initialize model layers here\n",
    "        self.conv2d_1 = nn.Conv2d(1, 32, (3, 3))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool2d= nn.MaxPool2d((2, 2)) \n",
    "        self.conv2d_2 = nn.Conv2d(32, 64, (3,3)) \n",
    "        self.flatten = Flatten() \n",
    "        self.linear1 = nn.Linear(2880, 64) \n",
    "        self.dropout = nn.Dropout(p=0.5, inplace=False) \n",
    "        self.linear2 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Use model layers to predict the two digits\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        out_first_digit = x[:, :10]\n",
    "        out_second_digit = x[:, 10:]\n",
    "\n",
    "        return out_first_digit, out_second_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47870b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train, y_train, X_test, y_test = U.get_data(path_to_data_dir, use_mini_dataset)\n",
    "\n",
    "    # Split into train and dev\n",
    "    dev_split_index = int(9 * len(X_train) / 10)\n",
    "    X_dev = X_train[dev_split_index:]\n",
    "    y_dev = [y_train[0][dev_split_index:], y_train[1][dev_split_index:]]\n",
    "    X_train = X_train[:dev_split_index]\n",
    "    y_train = [y_train[0][:dev_split_index], y_train[1][:dev_split_index]]\n",
    "\n",
    "    permutation = np.array([i for i in range(len(X_train))])\n",
    "    np.random.shuffle(permutation)\n",
    "    X_train = [X_train[i] for i in permutation]\n",
    "    y_train = [[y_train[0][i] for i in permutation], [y_train[1][i] for i in permutation]]\n",
    "\n",
    "    # Split dataset into batches\n",
    "    train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "    dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "    test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "    # Load model\n",
    "    input_dimension = img_rows * img_cols\n",
    "    model = CNN(input_dimension) # TODO add proper layers to CNN class above\n",
    "\n",
    "    # Train\n",
    "    train_model(train_batches, dev_batches, model)\n",
    "\n",
    "    ## Evaluate the model on test data\n",
    "    loss, acc = run_epoch(test_batches, model.eval(), None)\n",
    "    print('Test loss1: {:.6f}  accuracy1: {:.6f}  loss2: {:.6f}   accuracy2: {:.6f}'.format(loss[0], acc[0], loss[1], acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e3d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/562 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11500/3270429643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12321\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12321\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11500/460137372.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m## Evaluate the model on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MIT\\PROJECTS\\PROJECT 2 CNN MNIST\\mnist\\part2-twodigit\\train_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_data, dev_data, model, lr, momentum, nesterov, n_epochs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Run **training***\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train | loss1: {:.6f}  accuracy1: {:.6f} | loss2: {:.6f}  accuracy2: {:.6f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MIT\\PROJECTS\\PROJECT 2 CNN MNIST\\mnist\\part2-twodigit\\train_utils.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(data, model, optimizer)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# Predict and store accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mpredictions_first_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mpredictions_second_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mbatch_accuracies_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_first_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mbatch_accuracies_second\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_second_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Specify seed for deterministic behavior, then shuffle. Do not change seed for official submissions to edx\n",
    "    np.random.seed(12321)  # for reproducibility\n",
    "    torch.manual_seed(12321)  # for reproducibility\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
